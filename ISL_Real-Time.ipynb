{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"isl_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0:'1', \n",
    "                 1:'2', \n",
    "                 2:'3', \n",
    "                 3:'4', \n",
    "                 4:'5', \n",
    "                 5:'6',\n",
    "                 6:'7',\n",
    "                 7:'8',\n",
    "                 8:'9',\n",
    "                 9:'A',\n",
    "                 10:'B',\n",
    "                 11:'C',\n",
    "                 12:'D',\n",
    "                 13:'E',\n",
    "                 14:'F',\n",
    "                 15:'G',\n",
    "                 16:'H',\n",
    "                 17:\"I\",\n",
    "                 18:'J',\n",
    "                 19:'K',\n",
    "                 20:'L', \n",
    "                 21:'M', \n",
    "                 22:'N',\n",
    "                 23:'O',\n",
    "                 24:'P',\n",
    "                 25:'Q',\n",
    "                 26:'R',\n",
    "                 27:'S',\n",
    "                 28:'T',\n",
    "                 29:'U',\n",
    "                 30:'V',\n",
    "                 31:'W',\n",
    "                 32:'X',\n",
    "                 33:'Y',\n",
    "                 34:'Z'}\n",
    "color_dict=(0,255,0)\n",
    "x=0\n",
    "y=0\n",
    "w=64\n",
    "h=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Real-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_size=128\n",
    "minValue = 70\n",
    "source=cv2.VideoCapture(0)\n",
    "count = 0\n",
    "string = \" \"\n",
    "prev = \" \"\n",
    "prev_val = 0\n",
    "while(True):\n",
    "    ret,img=source.read()\n",
    "    img = cv2.flip(img,1)\n",
    "    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.rectangle(img,(x,y),(x+w,y+h),color_dict,2)\n",
    "    cv2.rectangle(img,(380,12),(600 , 250),color_dict,2)\n",
    "    crop_img=gray[12:250,380:600]\n",
    "    count = count + 1\n",
    "    if(count % 100 == 0):\n",
    "        prev_val = count\n",
    "    cv2.putText(img, str(prev_val//100), (300, 150),cv2.FONT_HERSHEY_SIMPLEX,1.5,(255,255,255),2) \n",
    "    blur = cv2.GaussianBlur(crop_img,(5,5),2)\n",
    "    th3 = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV,11,2)\n",
    "    ret, res = cv2.threshold(th3, minValue, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    resized=cv2.resize(res,(img_size,img_size))\n",
    "    normalized=resized/255.0\n",
    "    reshaped=np.reshape(normalized,(1,img_size,img_size,1))\n",
    "    result = model.predict(reshaped)\n",
    "    #print(result)\n",
    "    label=np.argmax(result,axis=1)[0]\n",
    "    if(count == 300):\n",
    "        count = 99\n",
    "        prev= labels_dict[label] \n",
    "        if(label == 0):\n",
    "               string = string + \" \"\n",
    "            #if(len(string)==1 or string[len(string)] != \" \"):\n",
    "             \n",
    "        else:\n",
    "                string = string + prev\n",
    "    \n",
    "    cv2.putText(img, prev, (24, 14),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2) \n",
    "    cv2.putText(img, string, (275, 50),cv2.FONT_HERSHEY_SIMPLEX,0.8,(200,200,200),2)\n",
    "    cv2.imshow(\"Gray\",res)    \n",
    "    cv2.imshow('LIVE',img)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    " \n",
    "    if(key==27):#press Esc. to exit\n",
    "        break\n",
    "print(string)        \n",
    "cv2.destroyAllWindows()\n",
    "source.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtts import gTTS \n",
    "  \n",
    "# This module is imported so that we can  \n",
    "# play the converted audio \n",
    "import os \n",
    "  \n",
    "# The text that you want to convert to audio \n",
    "  \n",
    "# Language in which you want to convert \n",
    "language = 'en'\n",
    "# Passing the text and language to the engine,  \n",
    "# here we have marked slow=False. Which tells  \n",
    "# the module that the converted audio should  \n",
    "# have a high speed \n",
    "myobj = gTTS(text=string, lang=language, slow=False) \n",
    "  \n",
    "# Saving the converted audio in a mp3 file named \n",
    "# welcome  \n",
    "myobj.save(\"welcome2121.mp3\") \n",
    "  \n",
    "# Playing the converted file \n",
    "os.system(\"welcome.mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
